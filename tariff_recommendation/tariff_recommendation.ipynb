{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Цель исследования:\n",
    "Построить наиболее качественную модель, которая выберет подходящий тариф для клиента оператора мобильной связи «Мегалайн».\n",
    "\n",
    "###### Ход исследования:\n",
    "1. Открыть и изучить предоставленные данные и подготовить их к исследованию при необходимости.\n",
    "2. Разделить исходные данные на обучающую, валидационную и тестовую выборки.\n",
    "3. Исследовать качество разных моделей, меняя гиперпараметры.\n",
    "4. Проверить качество модели на тестовой выборке.\n",
    "5. Проверить модель на вменяемость.\n",
    "6. Сделать вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем файл с данными и изучим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.0</td>\n",
       "      <td>560.51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9619.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.0</td>\n",
       "      <td>344.32</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19898.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51.0</td>\n",
       "      <td>437.13</td>\n",
       "      <td>61.0</td>\n",
       "      <td>21523.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56.0</td>\n",
       "      <td>433.07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16702.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108.0</td>\n",
       "      <td>587.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14406.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>22.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2710.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>588.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26.0</td>\n",
       "      <td>163.62</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16870.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>79.0</td>\n",
       "      <td>532.62</td>\n",
       "      <td>90.0</td>\n",
       "      <td>19908.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49.0</td>\n",
       "      <td>341.67</td>\n",
       "      <td>81.0</td>\n",
       "      <td>11770.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    calls  minutes  messages   mb_used  is_ultra\n",
       "0    40.0   311.90      83.0  19915.42         0\n",
       "1    85.0   516.75      56.0  22696.96         0\n",
       "2    77.0   467.66      86.0  21060.45         0\n",
       "3   106.0   745.53      81.0   8437.39         1\n",
       "4    66.0   418.74       1.0  14502.75         0\n",
       "5    58.0   344.56      21.0  15823.37         0\n",
       "6    57.0   431.64      20.0   3738.90         1\n",
       "7    15.0   132.40       6.0  21911.60         0\n",
       "8     7.0    43.39       3.0   2538.67         1\n",
       "9    90.0   665.41      38.0  17358.61         0\n",
       "10   82.0   560.51      20.0   9619.53         1\n",
       "11   45.0   344.32      13.0  19898.81         0\n",
       "12   51.0   437.13      61.0  21523.58         0\n",
       "13   56.0   433.07      16.0  16702.36         0\n",
       "14  108.0   587.90       0.0  14406.50         1\n",
       "15    6.0    22.13       0.0   2710.09         0\n",
       "16    2.0    18.73       0.0    588.89         0\n",
       "17   26.0   163.62       4.0  16870.34         0\n",
       "18   79.0   532.62      90.0  19908.31         0\n",
       "19   49.0   341.67      81.0  11770.28         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл действительно содержит данные, заявленные в документах к нему.\n",
    "На всякий случай проверим данные на пропуски и явные дубликаты, несмотря на то, что заявлено о их полной готовности к исследованию. Изменения типов данных не требуются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков и дубликатов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: данные изучены. в предобработке дополнительно не нуждаются. Таблица содержит все необходимые данные, которые и были заявлены в документах. Можно приступать к работе над основной задачей - построению модели по рекоммендации тарифа пользователям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Объявим две переменные - признаки (features) и целевой признак (target). Целевым признаком будет являться колонка \tis_ultra, остальные колонки таблицы - это features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3214, 4)\n",
      "(3214,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак данные разделены на признаки и целевой признак. Далее нужно разделить все данные на обучающую, валидационную и тестовую выборки. Данные должны быть разбиты в соотношении 3:1:1 соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Выделим обучающую выборку. Она должна составить 60% от всего массива данных. Для начала выделим его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.4, random_state=12345) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер обучающей выборки получился такой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(1928,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>ОТЛИЧНО! 👍</b>\n",
    "\n",
    "Молодец, что после разбиения данных на выборки смотришь на их размеры и размерности. Метод shape для этого - идеальный помощник. \"Цифры\" по выборкам показывают верно ли мы произвели \"разделение\" данных.\n",
    "\n",
    "p.s. так (**псевдокод**): X_train.shape[0] – «покажет» количество строк в тренировочной выборке, а X_train.shape[1] - количество столбцов в ней же. Ну а X_train.shape – выведет размерность train'а в виде кортежа с 2мя значениями (первое число – количество строк, второе – столбцов).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Оставшиеся 40% данных разделим пополам на валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_valid, features_test, target_valid, target_test = train_test_split(features_test, \n",
    "                                                                            target_test, \n",
    "                                                                            test_size=0.5, \n",
    "                                                                            random_state=12345\n",
    "                                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий 👉</b>\n",
    "\n",
    "Обрати внимание на ячейку, которую я сейчас комментирую – видишь слайдер («бегунок») снизу? Он показывает, что код не помещается в видимые границы ячейки (и чтобы его полностью «прочитать» - нужно использовать мышь. Код очень длинный.\n",
    "\n",
    "Код очень длинный (а PEP8 определяет длину строки в 79 символов) - попробуй длинные - переносить, а между строками использовать пустые строки. Ну и желательно код комментировать, хотя бы коротко (что делаешь и каков будет результат - так твоим коллегам будет проще за твоей мыслью следить). Этот комментарий может относиться к нескольким ячейкам этой «тетрадки».\n",
    "\n",
    "Хороший разработчик форматирует и комментирует свой код, тогда другие разработчики быстрее разберутся в программе. Это важно, ведь код чаще читают, чем пишут: напишет один, а прочтут — сотни или тысячи (если код хороший). \n",
    "«Пишите код так, как будто сопровождать его будет склонный к насилию психопат, который знает, где вы живете.» ©1991, John F. Woods, разработчик\n",
    "\n",
    "---\n",
    "Давай обсудим стиль кодирования (программирования)? Смотри что сейчас происходит в этой ячейке (**не всё применимо к твоему коду здесь, но я попытался собрать и представить здесь самые ценные советы из PEP8 по организации кода**) и что можно сделать по-другому, чуть лучше:\n",
    "\n",
    "1. Комментарии к строке кода: они должны располагаться выше соответствующей строки кода (выше строки к которой относятся) и должны быть от этой строки отделены пустой строкой. Если же они расположены справа, то для того чтобы увидеть, что там написано приходится пользоваться скроллиногом. Надо добиться того, чтобы ячейку не приходилось прокручивать, т.к. это не добавляет удобства ни при отладке кода, ни для понимания что в этой ячейке \"происходит\". Как альтернатива – комментарий может размещаться выше, в Markdown-ячейке.\n",
    "    \n",
    "2. Бывает, что встречаются очень длинные строки кода, которые также уходят за правый край ячейки. Такие строки должны разбиваться разделителем (вот таким: \\\\). Это best practice, требование PEP8, а именно: PEP8 определяет длину строки в 79 символов.\n",
    "    \n",
    "3. **В идеале**: одна ячейка - одна строка кода. Почему так? Да как минимум из соображения понятности: будучи выполненной, под этой ячейкой должен отображаться результат трансформации данных. Ты или твой коллега должны видеть, как поменялись данные после выполнения ячейки с кодом. Следующая ячейка - ещё строка кода и соответствующим output'ом. Будешь делать так - коллеги будут тебе благодарны за то, что легко будут следовать за твоей мыслью. И отладку это упрощает. Ну и как противоположность - можно в одну ячейку \"положить\" результат 3-х последовательных groupby + ещё чего-нибудь. Разобраться с ходу \"что происходит\" будет очень трудно, придётся всё равно код разносить по ячейкам и смотреть последовательно что происходит. Но ведь логично это делать удобным способом сразу, ведь так?\n",
    "    \n",
    "4. Неиспользуемые, закомментированные строки выше вынеси в другую ячейку, отдельную, выше. Можешь для удобства своего прокомментировать (на память). И оставь там это код, так, чтобы он не смешивался с рабочим кодом.\n",
    "\n",
    "p.s. возможно и в следующих ячейках твоей «тетрадки» будет код, который просмотреть можно только используя мышку, но я этот момент более комментировать не буду – просто обращай внимание на слайдер под ячейкой с кодом.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Перенесла строчки кода, теперь не нужно скроллить. Спасибо.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер валидационной выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "print(features_valid.shape)\n",
    "print(target_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер тестовой выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: данные разделены на обучающую, валидационную и тестовую выборки в соотношении 3:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий 👉</b>\n",
    "\n",
    "Один момент \"на будущее\" (сейчас забегаю чуть вперед, но будущем это будет важно) который я хотел озвучить перед переходом к работе с моделями:\n",
    "\n",
    "В наших данных есть числовые признаки (причём резко отличаюшиеся по значению модуля ... есть значения около 1 (маленькие, например *messages*) и десятки тысяч (большие, например *mb_used*). Линейные модели очень не любят подобные \"разбеги\" (вернее любят ))) потому что очень легко видят подобную разницу и придают бОльшим значениям бОльший вес в модели). После разделения данных на выборки, именно после разделения(!) следует отмасштабировать числовые столбцы. Используй StandardScaler() для этого.\n",
    "\n",
    "Для чего нужно масштабировать признаки перед подачей в линейную модель машинного обучения (в линейную регрессию, в логистическую регрессию)? Нам нужно минимизировать функцию потерь методом градиентного спуска. В случае разных масштабов признаков (например, год рождения и количество детей) её линии уровня будут иметь вид вытянутых эллипсов. Тогда вектор антиградиента и направление от текущей точки к минимуму функции потерь могут не совпадать, мы можем уйти далеко и не в ту сторону, и, в зависимости от шага градиентного спуска, либо придётся сделать больше итераций, либо вообще не будет сходимости. Если же признаки отмасштабированы, то линии уровня похожи на окружности. И проблема несовпадения антиградиента и направления к минимуму не так выражена.\n",
    "    \n",
    "Таким образом, масштабирование признаков перед подачей их в логистическую регрессию имеет несколько причин и преимуществ:\n",
    "\n",
    "- **Повышение стабильности и скорости сходимости**: Масштабирование признаков может помочь повысить стабильность и скорость сходимости алгоритма оптимизации, который используется при обучении логистической регрессии. Без масштабирования, признаки с большими значениями могут преобладать над признаками с меньшими значениями, что может замедлить сходимость алгоритма. Масштабирование позволяет привести все признаки к более сопоставимым диапазонам значений и улучшить процесс оптимизации.\n",
    "\n",
    "- **Предотвращение проблем с градиентным спуском**: Градиентный спуск, используемый для оптимизации параметров логистической регрессии, может быть чувствителен к различным масштабам признаков. Если признаки имеют большие значения, градиенты могут быть слишком большими, что может привести к проблемам с численной стабильностью и затуханию градиентов. Масштабирование признаков помогает справиться с этими проблемами, нормализуя их значения.\n",
    "\n",
    "- **Улучшение интерпретируемости**: Масштабирование признаков также может улучшить интерпретируемость модели. Когда признаки имеют разные диапазоны значений, сложнее понять, какой признак оказывает большее влияние на результаты модели. Масштабирование признаков позволяет сравнивать их вклады более непосредственно и делать более точные выводы о важности каждого признака.\n",
    "\n",
    "В целом, хорошей практикой является проведение экспериментов с масштабированием и без него, и сравнение результатов моделей на валидационной выборке или с помощью кросс-валидации. Это поможет определить, как масштабирование признаков влияет на производительность и результаты модели в нашей конкретной задаче (но если стоит вопрос: масштабировать или не масштабировать, то ИМХО ответ однозначен: ДА, МАСШТАБИРОВАТЬ).\n",
    "\n",
    "Ну и чуть-чуть теории (знаю, что в Тренажере этот момент вам пока не озвучивали): для масштабирования данных в линейной регрессии можно использовать различные методы, например стандартизацию (Standardization) и нормализацию (Normalization). Рассмотрим каждый из них с примерами кода (естественно используем наш scikit-learn).\n",
    "\n",
    "**Стандартизация (Standardization):**\n",
    "При стандартизации данные приводятся к стандартному нормальному распределению со средним значением 0 и стандартным отклонением 1. Это делается путем вычитания среднего значения и деления на стандартное отклонение каждого признака.\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Создание объекта для стандартизации данных\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Масштабирование обучающего набора данных\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Масштабирование тестового набора данных\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "**Нормализация (Normalization):**\n",
    "При нормализации данные приводятся к интервалу от 0 до 1 путем масштабирования каждого признака по его минимальному и максимальному значению.    \n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # Создание объекта для нормализации данных\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Масштабирование обучающего набора данных\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Масштабирование тестового набора данных\n",
    "    X_test_scaled = scaler.transform(X_test)    \n",
    "    \n",
    "Обрати внимание, что данные масштабируются отдельно для каждого признака на основе значений в обучающем наборе данных. Затем трансформированные значения применяются как для обучающего, так и для тестового наборов данных <- ЭТО ОЧЕНЬ ВАЖНЫЙ МОМЕНТ (и здесь часто ошибки встречаются)!!!\n",
    "\n",
    "Важно помнить, что масштабирование данных применяется только к признакам, а целевую переменную (выходные данные) необходимо оставить без изменений.\n",
    "\n",
    "Выбор между стандартизацией и нормализацией зависит от конкретной задачи и характеристик данных. Рекомендуется экспериментировать с обоими методами и выбрать наиболее подходящий для конкретного случая (но по опыту скажу, что обычно ограничиваются стандартизацией).    \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Спасибо!</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий 👉</b>\n",
    "\n",
    "Отлично, 5 шагов (EDA, обработка аномалий и пропусков, разделение данных на выборки, масштабирование/нормировку и кодирование признаков), входящие в типичный пайплайн подготовки данных **к этому моменту МОГУТ быть выполнены** ...\n",
    "\n",
    "Я тебе совет дам: создай шаблон кода (или функцию/функции), которые будут работать с момента загрузки данных и до получения выборок, готовых к передаче в модели МО.\n",
    "    \n",
    "Зачем такой шаблон нужен? Чтобы не ломать всякий раз голову, не вспоминать и писать руками один и тот же код (да ещё и с возможностью совершить \"глупую\" ошибку). В шаблоне должны быть (как минимум) следующие рутинные процедуры, которые встречаются ну абсолютно в каждом МО-проекте:\n",
    "    \n",
    "1. разбиение данных на выборки,\n",
    "\n",
    "2. масштабирование/нормировка.    \n",
    "\n",
    "3. обработка категорий,\n",
    "    \n",
    "Затем ты этот шаблон будешь вставлять в каждый новый проект, чуть модифицировать его (имена переменных, названия столбцов) и гарантированно получать работающий и безошибочный код.\n",
    "    \n",
    "А ресурсы головы ))) лучше тратить на подбор гиперпараметров и генерацию новых фичей - вот здесь находится то, что способно выделить твои модели, поднять их качество.    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Спасибо за совет.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>КОММЕНТАРИЙ V2</b> \t\n",
    "\n",
    "Вот пример ЧЕРНОВИКА шаблона пайплайна обработки данных для машинного обучения, включающий деление данных на выборки, кодирование категориальных переменных и масштабирование числовых переменных:\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "    # 1. Загрузка и подготовка данных\n",
    "    # Загрузка данных\n",
    "    data = ...\n",
    "\n",
    "    # Разделение на признаки (X) и целевую переменную (y)\n",
    "    X = data.drop(columns=['target'])\n",
    "    y = data['target']\n",
    "\n",
    "    # 2. Разделение данных на обучающую, валидационную и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 3. Создание пайплайна обработки данных\n",
    "    # Предобработка числовых переменных\n",
    "    numeric_features = [...]  # список числовых переменных\n",
    "\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    # Предобработка категориальных переменных\n",
    "    categorical_features = [...]  # список категориальных переменных\n",
    "\n",
    "    categorical_transformer = OneHotEncoder()\n",
    "\n",
    "    # Комбинированный препроцессор для числовых и категориальных переменных\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "    # 4. Создание пайплайна для обучения модели\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('regressor', LinearRegression())])\n",
    "\n",
    "    # 5. Обучение модели\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 6. Оценка модели\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    val_score = model.score(X_val, y_val)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    # Вывод результатов\n",
    "    print('Train Score:', train_score)\n",
    "    print('Validation Score:', val_score)\n",
    "    print('Test Score:', test_score)\n",
    "    \n",
    "    \n",
    "В данном примере:\n",
    "\n",
    "Шаг 1: Загружаются и подготавливаются данные.\n",
    "    \n",
    "Шаг 2: Данные разделяются на обучающую, валидационную и тестовую выборки с помощью функции train_test_split().\n",
    "    \n",
    "Шаг 3: Создается пайплайн обработки данных с использованием ColumnTransformer, который применяет соответствующие преобразования к числовым и категориальным переменным.\n",
    "    \n",
    "Шаг 4: Создается пайплайн для обучения модели, включающий предобработку данных и модель.\n",
    "    \n",
    "Шаг 5: Модель обучается на обучающих данных с помощью метода fit().\n",
    "    \n",
    "Шаг 6: Оценивается производительность модели на обучающей, валидационной и тестовой выборках с помощью метода score().    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как задача на классификацию (задача модели выбрать для аббонента один из двух возможных тарифов - Смарт(0) или Ультра(1)), для ее решения будем использовать соответствующие модели:\n",
    "1. Решающее дерево(DecisionTreeClassifier)\n",
    "2. Случайный лес(RandomForestClassifier)\n",
    "3. Логистическая регрессия(LogisticRegression)\n",
    "\n",
    "Для проверки качества моделей будем использовать метрику accuracy. Чем больше получится данный показатель, тем более качественна модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель 1. Решающее дерево(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем код, который позволит нам выбрать наиболее качественную из возможных вариантов модели Решающего дерева. Для этого будем перебирать гиперпараметр max_depth от 1 до 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.7853810264385692\n",
      "Глубина лучшей модели: 3\n"
     ]
    }
   ],
   "source": [
    "best_model_tree = None\n",
    "best_depth_tree = 0\n",
    "best_result_tree = 0\n",
    "for depth in range(1, 11):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth = depth)\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    predictions_valid_tree = model_tree.predict(features_valid)\n",
    "    result_tree = accuracy_score(target_valid, predictions_valid_tree)\n",
    "    if result_tree > best_result_tree:\n",
    "        best_model_tree = model_tree\n",
    "        best_depth_tree = depth\n",
    "        best_result_tree = result_tree\n",
    "        \n",
    "print(\"Accuracy лучшей модели:\", best_result_tree)\n",
    "print (\"Глубина лучшей модели:\", best_depth_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий 👉</b>\n",
    "\n",
    "Рекомендую перебрать в цикле 2-3 гиперпараметра. Одного, как для \"дерева\", так и \"леса\" мало - точность наверняка будет низкой. В итоге получишь сразу два плюса: потренируешся работать с несколькими гиперпараметрами одновременно и получишь более высокую точность моделей!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Например, так как я написала ниже? Добавить в цикл перебор гиперпараметра min_samples_split. Если так, то это действительно влияет на качество модели. Качество модели решающего дерева увеличилось с 0.785 до 0.819 если ограничить количество узлов, которые создает модель. </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>КОММЕНТАРИЙ V2</b> \t\n",
    "\n",
    "Да, всё верно, как ниже, двойной цикл.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.8193146417445483\n",
      "Глубина лучшей модели: 7\n",
      "Vинимальное количество примеров для разделения лучшей модели: 2\n"
     ]
    }
   ],
   "source": [
    "best_model_tree = None\n",
    "best_depth_tree = 0\n",
    "best_split_tree = 0\n",
    "best_result_tree = 0\n",
    "for depth in range(1, 11):\n",
    "    for split in range(2, 5):\n",
    "        model_tree = DecisionTreeClassifier(random_state=12345, max_depth = depth, min_samples_split = split)\n",
    "        model_tree.fit(features_train, target_train)\n",
    "        predictions_valid_tree = model_tree.predict(features_valid)\n",
    "        result_tree = accuracy_score(target_valid, predictions_valid_tree)\n",
    "        if result_tree > best_result_tree:\n",
    "            best_model_tree = model_tree\n",
    "            best_depth_tree = depth\n",
    "            best_split_tree = split\n",
    "            best_result_tree = result_tree\n",
    "        \n",
    "print(\"Accuracy лучшей модели:\", best_result_tree)\n",
    "print (\"Глубина лучшей модели:\", best_depth_tree)\n",
    "print (\"Минимальное количество примеров для разделения лучшей модели:\", best_split_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Качество (accuracy) лучшей модели Решающего дерева из исследуемых десяти равно 0.7853810264385692 при гиперпараметре max_depth равном 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель 2. Случайный лес(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично исследуем модель Случайный лес. В данном случае нужно будет найти лучший параметр accuracy, перебирая не только глубину, но и количество деревьев. Для исследования возьмем глубину от 1 до 10, и количество деревьев от 1 до 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.8040435458786936\n",
      "Количество деревьев лучшей модели: 12\n",
      "Глубина лучшей модели: 6\n"
     ]
    }
   ],
   "source": [
    "best_model_forest = None\n",
    "best_est_forest = 0\n",
    "best_depth_forest = 0\n",
    "best_result_forest = 0\n",
    "for est in range(1, 21):\n",
    "    for depth in range(1, 11):\n",
    "        model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth = depth) \n",
    "        model_forest.fit(features_train, target_train)\n",
    "        predictions_valid_forest = model_forest.predict(features_valid)\n",
    "        result_forest = accuracy_score(target_valid, predictions_valid_forest)\n",
    "        if result_forest > best_result_forest:\n",
    "            best_model_forest = model_forest\n",
    "            best_est_forest = est\n",
    "            best_depth_forest = depth\n",
    "            best_result_forest = result_forest\n",
    "        \n",
    "print(\"Accuracy лучшей модели:\", best_result_forest)\n",
    "print(\"Количество деревьев лучшей модели:\", best_est_forest)\n",
    "print (\"Глубина лучшей модели:\", best_depth_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Ниже добавила в код модели леса тот же гиперпараметр min_samples_split. Качество так же возрасло. Единственное, такой код долго выполняется.</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>КОММЕНТАРИЙ V2</b> \t\n",
    "\n",
    "Ну да, с увеличением количества подбираемых гиперпараметров МОЖЕТ(!) улучшаться и метрика, но однозначно будет увеличиваться и время расчета.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy лучшей модели: 0.8348909657320872\n",
      "Количество деревьев лучшей модели: 6\n",
      "Глубина лучшей модели: 8\n",
      "Минимальное количество примеров для разделения лучшей модели: 3\n"
     ]
    }
   ],
   "source": [
    "best_model_forest = None\n",
    "best_est_forest = 0\n",
    "best_depth_forest = 0\n",
    "best_split_forest = 0\n",
    "best_result_forest = 0\n",
    "for est in range(1, 21):\n",
    "    for depth in range(1, 11):\n",
    "        for split in range(2, 5):\n",
    "            model_forest = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth = depth, \n",
    "                                                  min_samples_split = split) \n",
    "            model_forest.fit(features_train, target_train)\n",
    "            predictions_valid_forest = model_forest.predict(features_valid)\n",
    "            result_forest = accuracy_score(target_valid, predictions_valid_forest)\n",
    "            if result_forest > best_result_forest:\n",
    "                best_model_forest = model_forest\n",
    "                best_est_forest = est\n",
    "                best_depth_forest = depth\n",
    "                best_split_forest = split\n",
    "                best_result_forest = result_forest\n",
    "        \n",
    "print(\"Accuracy лучшей модели:\", best_result_forest)\n",
    "print(\"Количество деревьев лучшей модели:\", best_est_forest)\n",
    "print (\"Глубина лучшей модели:\", best_depth_forest)\n",
    "print (\"Минимальное количество примеров для разделения лучшей модели:\", best_split_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Качество (accuracy) лучшей модели Случайного леса из исследуемых равно 0.8040435458786936 при гиперпараметре max_depth равном 6, и количесве деревьев равном 12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель 3. Логистическая регрессия(LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же исследуем третью модель - Логистическую регрессию. Добавим гиперпараметры: solver='lbfgs' и max_iter=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LogisticRegression: 0.7107309486780715\n"
     ]
    }
   ],
   "source": [
    "model_regression = LogisticRegression(random_state=12345, solver='lbfgs', max_iter=1000)\n",
    "model_regression.fit(features_train, target_train)\n",
    "predictions_valid_regression = model_regression.predict(features_valid)\n",
    "result_regression = accuracy_score(target_valid, predictions_valid_regression)\n",
    "\n",
    "print(\"Accuracy LogisticRegression:\", result_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Accuracy модели LogisticRegression равно 0.7107309486780715"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод. \n",
    "\n",
    "Наиболее качественной себя показала модель Случайного леса(RandomForestClassifier).Ее показатель accuracy составил 0.8040435458786936 при гиперпараметре max_depth равном 6, и количесве деревьев равном 12.\n",
    "\n",
    "На втором месте по качеству оказалась модель Решающее дерево(DecisionTreeClassifier) с показателем accuracy 0.7853810264385692.\n",
    "\n",
    "Хуже всех по качеству оказалась модель Логистическая регрессия(LogisticRegression) с показателем accuracy 0.7107309486780715."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>ОТЛИЧНО! 👍</b>\n",
    "\n",
    "Здесь отлично: подобрали для всех наших моделей лучшие гиперпараметры (в данном случае - максимизирующие метрику accuracy_score). Также здесь мы ещё и определили САМУЮ лучшую модель. На валидации ею оказалась модель \"случайного леса\". \n",
    "\n",
    "После того, как гиперпараметры на валидации подобраны - тестируем модели на тестовых данных. По результатам тестирования на тесте (сорри за тавталогию) выбираем модель, которую сможем передать в продакшн. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее качественной себя показала модель Случайного леса(RandomForestClassifier). Проверим данную модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели случайного леса на тестовой выборке: 0.7947122861586314\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(random_state=12345, n_estimators = 12, max_depth = 6)\n",
    "model_forest.fit(features_train, target_train)\n",
    "predictions_test_forest = model_forest.predict(features_test)\n",
    "accuracy_test_forest = accuracy_score(target_test, predictions_test_forest)\n",
    "\n",
    "print(\"Accuracy модели случайного леса на тестовой выборке:\", accuracy_test_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>ОТЛИЧНО! 👍</b>\n",
    "\n",
    "Здесь отлично: проверили \"качество\" нашей лучшей модели на тестовых данных и поняли что можем запустить её в промышленную эксплуатацию!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод. \n",
    "Accuracy модели случайного леса на тестовой выборке составила 0.7947122861586314, что выше заданного обязательного параметра 0.75. Таким образом, делаем вывод, что выбранная модель работает успешно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью DummyClassifier создадим простейшую модель, которая будет предсказывать наиболее часто встречающийся класс. Найдем показатель accuracy для этой модели и сравним его с показателем accuracy для модели случайного леса, который показал свою эффективность в тестовой выборке в предыдущем задании. Если они будут различаться, значит модель адекватна, и обучилась верно, она действительно делает предсказание на основе всех параметров, и это не случайные предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели DummyClassifier: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "dummy_model = DummyClassifier(strategy='most_frequent', random_state=12345)\n",
    "dummy_model.fit(features_train, target_train)\n",
    "predictions_dummy = dummy_model.predict(features_test)\n",
    "print(\"Accuracy модели DummyClassifier:\", accuracy_score(target_test, predictions_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>ОТЛИЧНО! 👍</b>\n",
    "\n",
    "Верно, здесь мы используем простейшую (dummy) модель: DummyClassifier (для нашей задачи бинарной классификации). DummyClassifier \"предсказывает\" наиболее часто встречающийся класс. Здесь мы получаем контрольную accuracy, чтобы сравнить её с результатом работы нашей самой лучшей модели. Ну и конечно, из общих соображений понятно, что наша лучшая модель должна \"побить\" DummyClassifier.\n",
    "    \n",
    "p.s. (на перспективу!): можно было бы построить Confusion Matrix, чтобы детально посмотреть где ошибается модель. Подробнее о Confusion Matrix здесь: https://neptune.ai/blog/evaluation-metrics-binary-classification     \n",
    "\n",
    "p.s. ещё вариант - сравнить самый часто встречающийся класс в наших данных (это is_ultra == 0). Таких значений 2.229 в нашем датафрейме. Всего же значений в датафрейме 3.214. Значит самый часто встречающийся класс \"занимает\" 69% (2229 / 3214 == 0.693528313627878). Вот мы и получили контрольные данные для сравнительной оценки, построенной нами \"лучшей\" модели. Наша лучшая модель должна \"побить\" этот скор.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #B0E0E6; padding: 5px; border: 1px solid SteelBlue; border-radius: 5px;\">\n",
    "    <font color='4682B4'><u><b>КОММЕНТАРИЙ СТУДЕНТА</b></u></font>\n",
    "    <br />\n",
    "    <font color='4682B4'>Спасибо за подсказки, изучу. Долго думала над этой задачей и изучала что такое DummyClassifier, до остальных способов просто не добралась) Теперь есть, что почитать и поразбираться. </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Модель Случайного леса, которую мы опрелили как качественную и успешную, адекватна, т.к. показатель Accuracy нашей модели составил 0.7947122861586314, что выше показателя Accuracy простейшей модели DummyClassifier (0.6842923794712286). Это значит, что наша модель делает не случайные предсказания.\n",
    "Кроме того, мы также можем сделать вывод, что каждая из построенных нами моделей в предыдущем задании, адекватна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Этап 1. Изучение данных.\n",
    "В ходе этого этапа был открыт файл и изучены данные. Они действительно соответствовали документации. Так же была проведена проверка на пропуски и дубликаты. Их обнаружено не было, предобработка данных не потребовалась.\n",
    "\n",
    "#### Этап 2. Разделение исходных данных на обучающую, валидационную и тестовую выборки.\n",
    "Данные были разделены на три выборки в соотношении 3:1:1. 60% данных было отведено на обучающую выборку, 20% - на валидационную и еще 20% на тестовую.\n",
    "\n",
    "#### Этап 3. Исследование качества разных моделей.\n",
    "В ходе работы были исследованы 3 разных модели:\n",
    "1. Решающее дерево(DecisionTreeClassifier)\n",
    "2. Случайный лес(RandomForestClassifier)\n",
    "3. Логистическая регрессия(LogisticRegression)\n",
    "Для проверки качества моделей была использована метрика accuracy.\n",
    "\n",
    "Наиболее качественной себя показала модель Случайного леса(RandomForestClassifier).Ее показатель accuracy составил 0.8040435458786936 при гиперпараметре max_depth равном 6, и количесве деревьев равном 12.\n",
    "На втором месте по качеству оказалась модель Решающее дерево(DecisionTreeClassifier) с показателем accuracy 0.7853810264385692.\n",
    "Хуже всех по качеству оказалась модель Логистическая регрессия(LogisticRegression) с показателем accuracy 0.7107309486780715.\n",
    "\n",
    "#### Этап 4. Проверка качества модели на тестовой выборке.\n",
    "На тестовой выборке была проверена модель Случайного леса(RandomForestClassifier), которая показала наиболее высокий показатель качества. Accuracy модели случайного леса на тестовой выборке составила 0.7947122861586314, что всего на 0.01 меньше, чем на валидационной. Модель рабочая.\n",
    "\n",
    "#### Этап 5. Проверка модели на адекватность.\n",
    "Была создана простейшая модель, которая предсказывает наиболее часто встречающийся класс. В результате сравнения качества простейшей модели и выбранной нами эффективной модели, было выявлено, что показатель Accuracy нашей модели составил 0.7947122861586314, это выше показателя Accuracy простейшей модели DummyClassifier (0.6842923794712286). Это значит, что наша модель делает не случайные предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>ОТЛИЧНО! 👍</b>\n",
    "\n",
    "Всё отлично, результат достигнут.\n",
    "    \n",
    "Один совет (также, на будущее): как попытаться улучшить полученный результат, с минимум усилий? Ответ: мы использовали train для обучения модели, а valid - для поиска лучших значений гиперпараметров. Лучшие параметры нашли. Так почему бы теперь наши модели с выбранными гиперпараметрами не обучить на *общей* (тренировочной + валидационной) выборке (pd.concat() можно использовать для объединения). Чем больше данных, тем *лучше* модели смогут обучиться (надо проверять!). И вот теперь эту дообученную модель мы уже финально проверим на тестовой выборке (test).\n",
    "\n",
    "Но следует учесть вот какой момент: нужно быть аккуратным с подобным «улучшением», если мы кодируем или масштабируем наши выборки. Например, в следующем проекте мы обучаемся на train’е, а затем делаем transform на валидации и тесте. Если после этого объединить трейн и валид, то это будет не совсем верно.\n",
    "\n",
    "p.s. а вообще, достижение высокого скора не такая простая задача. Много моментов может влиять (подбор гиперпараметров - всего лишь один из них). В этой конкретно задаче мне кажется, что данных маловато, а также, возможно и фичей (столбцов в наших данных). Из-за этого модели не могут точно \"настроиться на данные\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>ОТЛИЧНО! 👍</b>\n",
    "\n",
    "Елизавета, у тебя хорошая работа, все четко, осмысленно. Выводы присутствуют, с комментированием кода тоже никаких проблем нет.\n",
    "\n",
    "Я оставил ряд советов на будущее (на результат этого проекта они не влияют). \n",
    "\n",
    "Я отправляю тебе проект ещё раз лишь для того, чтобы удостовериться что у тебя нет вопросов ко мне. Если их нет - пошли мне тетрадку ещё раз, и я тут же, без слов приму твою работу! \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 48,
    "start_time": "2023-07-14T07:49:05.983Z"
   },
   {
    "duration": 423,
    "start_time": "2023-07-14T07:49:07.981Z"
   },
   {
    "duration": 149,
    "start_time": "2023-07-14T07:49:08.408Z"
   },
   {
    "duration": 50,
    "start_time": "2023-07-14T07:49:14.438Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-14T07:50:16.466Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-14T07:50:23.942Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-14T07:51:29.954Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-14T07:52:23.878Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-14T08:03:57.340Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-14T08:04:43.623Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-14T08:04:50.734Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-14T08:04:56.543Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-14T08:05:05.937Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-14T08:15:49.679Z"
   },
   {
    "duration": 1186,
    "start_time": "2023-07-14T08:16:18.482Z"
   },
   {
    "duration": 52,
    "start_time": "2023-07-14T08:16:19.670Z"
   },
   {
    "duration": 46,
    "start_time": "2023-07-14T08:16:19.723Z"
   },
   {
    "duration": 143,
    "start_time": "2023-07-14T08:16:19.772Z"
   },
   {
    "duration": 64,
    "start_time": "2023-07-14T08:16:19.916Z"
   },
   {
    "duration": 67,
    "start_time": "2023-07-14T08:16:19.982Z"
   },
   {
    "duration": 118,
    "start_time": "2023-07-14T08:16:20.051Z"
   },
   {
    "duration": 96,
    "start_time": "2023-07-14T08:16:20.170Z"
   },
   {
    "duration": 59,
    "start_time": "2023-07-14T08:16:20.267Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-14T08:16:54.830Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-14T08:17:16.610Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-14T08:20:02.315Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-14T08:21:06.953Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-14T08:21:41.483Z"
   },
   {
    "duration": 1483,
    "start_time": "2023-07-14T08:43:53.618Z"
   },
   {
    "duration": 52,
    "start_time": "2023-07-14T08:43:55.103Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-14T08:43:55.157Z"
   },
   {
    "duration": 23,
    "start_time": "2023-07-14T08:43:55.172Z"
   },
   {
    "duration": 23,
    "start_time": "2023-07-14T08:43:55.198Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-14T08:43:55.224Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-14T08:43:55.233Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-14T08:43:55.250Z"
   },
   {
    "duration": 27,
    "start_time": "2023-07-14T08:43:55.273Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-14T08:43:55.302Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-14T08:43:55.320Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-14T08:43:55.338Z"
   },
   {
    "duration": 85,
    "start_time": "2023-07-14T08:43:55.348Z"
   },
   {
    "duration": 86,
    "start_time": "2023-07-14T08:46:33.309Z"
   },
   {
    "duration": 76,
    "start_time": "2023-07-14T08:59:54.943Z"
   },
   {
    "duration": 1375,
    "start_time": "2023-07-14T09:04:02.856Z"
   },
   {
    "duration": 51,
    "start_time": "2023-07-14T09:04:04.235Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-14T09:04:04.287Z"
   },
   {
    "duration": 33,
    "start_time": "2023-07-14T09:04:04.302Z"
   },
   {
    "duration": 44,
    "start_time": "2023-07-14T09:04:04.338Z"
   },
   {
    "duration": 38,
    "start_time": "2023-07-14T09:04:04.384Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-14T09:04:04.424Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-14T09:04:04.450Z"
   },
   {
    "duration": 21,
    "start_time": "2023-07-14T09:04:04.468Z"
   },
   {
    "duration": 30,
    "start_time": "2023-07-14T09:04:04.491Z"
   },
   {
    "duration": 19,
    "start_time": "2023-07-14T09:04:04.525Z"
   },
   {
    "duration": 31,
    "start_time": "2023-07-14T09:04:04.546Z"
   },
   {
    "duration": 100,
    "start_time": "2023-07-14T09:04:04.579Z"
   },
   {
    "duration": 22120,
    "start_time": "2023-07-14T09:04:27.028Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-14T09:05:46.582Z"
   },
   {
    "duration": 258,
    "start_time": "2023-07-14T09:06:14.848Z"
   },
   {
    "duration": 2034,
    "start_time": "2023-07-14T09:06:26.169Z"
   },
   {
    "duration": 6956,
    "start_time": "2023-07-14T09:06:37.733Z"
   },
   {
    "duration": 13685,
    "start_time": "2023-07-14T09:06:51.649Z"
   },
   {
    "duration": 6688,
    "start_time": "2023-07-14T09:07:39.497Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-14T09:15:58.210Z"
   },
   {
    "duration": 27,
    "start_time": "2023-07-14T09:26:54.688Z"
   },
   {
    "duration": 53,
    "start_time": "2023-07-14T09:28:25.819Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-14T10:32:50.557Z"
   },
   {
    "duration": 109,
    "start_time": "2023-07-14T10:41:15.245Z"
   },
   {
    "duration": 1178,
    "start_time": "2023-07-14T10:41:27.651Z"
   },
   {
    "duration": 58,
    "start_time": "2023-07-14T10:41:28.831Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-14T10:41:28.891Z"
   },
   {
    "duration": 71,
    "start_time": "2023-07-14T10:41:28.906Z"
   },
   {
    "duration": 60,
    "start_time": "2023-07-14T10:41:28.979Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-14T10:41:29.041Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-14T10:41:29.049Z"
   },
   {
    "duration": 49,
    "start_time": "2023-07-14T10:41:29.064Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-14T10:41:29.115Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-14T10:41:29.135Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-14T10:41:29.166Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-14T10:41:29.182Z"
   },
   {
    "duration": 87,
    "start_time": "2023-07-14T10:41:29.198Z"
   },
   {
    "duration": 6072,
    "start_time": "2023-07-14T10:41:29.287Z"
   },
   {
    "duration": 27,
    "start_time": "2023-07-14T10:41:35.362Z"
   },
   {
    "duration": 58,
    "start_time": "2023-07-14T10:41:35.391Z"
   },
   {
    "duration": 125,
    "start_time": "2023-07-14T10:41:35.451Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-14T10:41:59.964Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-14T10:44:08.676Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-14T10:49:05.165Z"
   },
   {
    "duration": 1172,
    "start_time": "2023-07-14T11:09:40.841Z"
   },
   {
    "duration": 51,
    "start_time": "2023-07-14T11:09:42.015Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-14T11:09:42.068Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-14T11:09:42.083Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-14T11:09:42.101Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-14T11:09:42.115Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-14T11:09:42.125Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-14T11:09:42.135Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-14T11:09:42.145Z"
   },
   {
    "duration": 30,
    "start_time": "2023-07-14T11:09:42.155Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-14T11:09:42.187Z"
   },
   {
    "duration": 21,
    "start_time": "2023-07-14T11:09:42.207Z"
   },
   {
    "duration": 89,
    "start_time": "2023-07-14T11:09:42.230Z"
   },
   {
    "duration": 6195,
    "start_time": "2023-07-14T11:09:42.321Z"
   },
   {
    "duration": 30,
    "start_time": "2023-07-14T11:09:48.518Z"
   },
   {
    "duration": 63,
    "start_time": "2023-07-14T11:09:48.550Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-14T11:09:48.615Z"
   },
   {
    "duration": 52,
    "start_time": "2023-07-14T12:55:36.314Z"
   },
   {
    "duration": 1256,
    "start_time": "2023-07-14T12:55:53.291Z"
   },
   {
    "duration": 138,
    "start_time": "2023-07-14T12:55:54.549Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-14T12:55:54.689Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-14T12:55:54.703Z"
   },
   {
    "duration": 8,
    "start_time": "2023-07-14T12:55:54.721Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-14T12:55:54.731Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-14T12:55:54.739Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-14T12:55:54.753Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-14T12:55:54.772Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-14T12:55:54.779Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-14T12:55:54.787Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-14T12:55:54.804Z"
   },
   {
    "duration": 77,
    "start_time": "2023-07-14T12:55:54.827Z"
   },
   {
    "duration": 5745,
    "start_time": "2023-07-14T12:55:54.906Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-14T12:56:00.653Z"
   },
   {
    "duration": 56,
    "start_time": "2023-07-14T12:56:00.680Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-14T12:56:00.737Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-14T12:56:11.236Z"
   },
   {
    "duration": 276,
    "start_time": "2023-07-14T13:01:16.268Z"
   },
   {
    "duration": 105,
    "start_time": "2023-07-14T13:10:30.342Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-14T13:11:04.240Z"
   },
   {
    "duration": 200,
    "start_time": "2023-07-14T13:11:28.502Z"
   },
   {
    "duration": 17011,
    "start_time": "2023-07-14T13:18:26.067Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
